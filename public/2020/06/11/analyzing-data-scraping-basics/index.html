<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.69.0" />


<title>Data reporting - web scraping basics - Brian&#39;s Data Blog</title>
<meta property="og:title" content="Data reporting - web scraping basics - Brian&#39;s Data Blog">


  <link href='/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">

<style>h1 {text-align:center;}</style>
<h1><img src="/images/mug011119_2.png" alt="My Ugly Mug" width=45 height=60>
Brian's Data Blog</h1>


  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/college_lodge.png"
         width="75"
         height="75"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/BrianOB/briandatablog">GitHub</a></li>
    
    <li><a href="">Gmail address: briandatablog</a></li>
    
    <li><a href="https://twitter.com/brianbupdate">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">5 min read</span>
    

    <h1 class="article-title">Data reporting - web scraping basics</h1>

    
    <span class="article-date">2020-06-11</span>
    

    <div class="article-content">
      
<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<link href="/rmarkdown-libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/datatables-binding/datatables.js"></script>
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="/rmarkdown-libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="/rmarkdown-libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/crosstalk/js/crosstalk.min.js"></script>


<div id="a-quick-look-at-web-scraping-data-cleaning-and-data-archiving" class="section level1">
<h1>A quick look at web scraping, data cleaning and data archiving</h1>
<p>This is more of a quick look at something I recently learned than anything exhaustive on the subject. What I learned is how to use <em>html_table()</em> in the <em>rvest</em> package to save myself a lot of headaches when it comes to scraping.</p>
<p>Typically when I scrape data from the site I figure out how to grab individual pieces of data, pull them into lists and then create a tibble (data frame) from the lists. But <em>html_table()</em> can often do all that for me since much of the data I’m seeking is already contained inside an HTML table.</p>
<p>For this example, I’m going to use IRE’s Job Center. I really don’t see an immediate application for the scraped data but, in theory, scraping it regularly over time would allow you to build up a database that would show which media outlets in which parts of the country are serious about hiring investigative/data journalists. An an unemployed data journalist, that is of some interest to me.</p>
<p>The basic process here is to scrape the job listings, including the url for the actual job listing into a tibble. After some data cleaning, I save the result to an RData file that I’ll update in future scrapes to build the database. One variable I use that doesn’t show up in this post is the path to where I’m saving the data since that’s specific to my computer. If you want to do the scrape yourself, you’ll need to save a path to the variable as follows:
save_path &lt;- ‘path to folder for saved data’</p>
<pre class="r"><code>library(tidyverse)  # general data toolbox
library(rvest)      # scraping toolbox
library(lubridate)  # date wrangling
library(janitor)    # data cleaning
library(DT)         # table building</code></pre>
<div id="reading-the-jobs-data-web-page" class="section level2">
<h2>Reading the jobs data web page</h2>
<p>This is fairly straightforward. I do it in two steps since I like to have the url value save separately, but there’s no reason you couldn’t combine the steps.</p>
<pre class="r"><code>url_page &lt;- &#39;https://www.ire.org/jobs&#39;
urls &lt;- read_html(url_page)</code></pre>
<p>As I said before, typically my next step would be a building a series of lists using a combination of html_nodes(), html_attr() and html_text() to grab the data, but html_table() handles all of that except for the urls, which I have to go old-school on.</p>
<pre class="r"><code>jobs &lt;- urls %&gt;% 
  html_table() %&gt;% 
  bind_cols(url = urls %&gt;% html_nodes(xpath=&#39;//td&#39;) %&gt;% 
  html_nodes(&#39;h4&#39;) %&gt;% 
  html_nodes(&#39;a&#39;) %&gt;% 
  html_attr(&#39;href&#39;)) %&gt;% 
  rename(title=X1, employer=X2, location=X3, posted=X4)</code></pre>
<p>Taking a look at the results, you can see a couple of issues. One is the unnecessary text in the location and posted fields and the second is that the posted field should probably be formatted as a date to be of any use.</p>
<pre class="r"><code>jobs %&gt;% 
  datatable(options=list(dom=&#39;t&#39;))</code></pre>
<div id="htmlwidget-1" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18"],["Digital Journalist (Political)","Digital Journalist","Managing Director, Digital (Midwest)","Director of Intelligence Project","McGraw Fellowship for Business Journalism","Investigative Media Journalist","Executive Producer","Knight Science Journalism at MIT 2020-21 Project Fellowship","Data Reporter","Audience Engagement Editor","Reporter","Data Reporter","Chief Revenue Officer","Data Reporter","Data Specialist","Editor-in-Chief","Editor-in-chief","Digital Outreach Director"],["Spectrum Networks","Spectrum Networks","Spectrum Networks","Intelligence Project","McGraw Center for Business Journalism","Dolcefino Consulting","Dolcefino Consulting","Knight Science Journalism Program","Louisville Public Media","The Marshall Project","The Press Democrat","WBUR","inewsource","Richmond Times-Dispatch","The Washington Post","The Simons Foundation","Spectrum","Global Investigative Journalism Network"],["Location:\n                Madison, WI","Location:\n                Cleveland, Ohio","Location:\n                Louisville, KY, Milwaukee, WI, Columbus, Ohio","Location:\n                Montgomery, Alabama or Atlanta","Location:\n                New York, NY","Location:\n                Houston, TX","Location:\n                Houston, TX","Location:\n                Remote","Location:\n                Louisville, KY","Location:\n                New York, NY","Location:\n                Santa Rosa, CA","Location:\n                Boston, MA","Location:\n                San Diego, CA","Location:\n                Richmond, VA","Location:\n                Washington, DC","Location:\n                New York, NY","Location:\n                New York, NY","Location:\n                Remote"],["Posted:\n                \n                    06.10.2020","Posted:\n                \n                    06.10.2020","Posted:\n                \n                    06.10.2020","Posted:\n                \n                    06.08.2020","Posted:\n                \n                    06.05.2020","Posted:\n                \n                    06.05.2020","Posted:\n                \n                    06.05.2020","Posted:\n                \n                    05.29.2020","Posted:\n                \n                    05.26.2020","Posted:\n                \n                    05.21.2020","Posted:\n                \n                    05.15.2020","Posted:\n                \n                    05.14.2020","Posted:\n                \n                    05.13.2020","Posted:\n                \n                    05.12.2020","Posted:\n                \n                    05.08.2020","Posted:\n                \n                    05.06.2020","Posted:\n                \n                    05.04.2020","Posted:\n                \n                    04.29.2020"],["https://www.ire.org/archives/jobs/job/digital-journalist-political","https://www.ire.org/archives/jobs/job/digital-journalist","https://www.ire.org/archives/jobs/job/managing-director-digital-midwest","https://www.ire.org/archives/jobs/job/director-of-intelligence-project","https://www.ire.org/archives/jobs/job/mcgraw-fellowship-for-business-journalism-4","https://www.ire.org/archives/jobs/job/investigative-media-journalist","https://www.ire.org/archives/jobs/job/executive-producer-6","https://www.ire.org/archives/jobs/job/knight-science-journalism-at-mit-2020-21-project-fellowship","https://www.ire.org/archives/jobs/job/data-reporter-16","https://www.ire.org/archives/jobs/job/audience-engagement-editor-2","https://www.ire.org/archives/jobs/job/reporter-11-1","https://www.ire.org/archives/jobs/job/data-reporter-15","https://www.ire.org/archives/jobs/job/chief-revenue-officer-2","https://www.ire.org/archives/jobs/job/data-reporter-14","https://www.ire.org/archives/jobs/job/data-specialist","https://www.ire.org/archives/jobs/job/editor-in-chief-4","https://www.ire.org/archives/jobs/job/editor-in-chief-3","https://www.ire.org/archives/jobs/job/digital-outreach-director"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>title<\/th>\n      <th>employer<\/th>\n      <th>location<\/th>\n      <th>posted<\/th>\n      <th>url<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"t","order":[],"autoWidth":false,"orderClasses":false,"columnDefs":[{"orderable":false,"targets":0}]}},"evals":[],"jsHooks":[]}</script>
<p>Both are easy to fix.</p>
<p>The <em>str_replace()</em> function from the <em>stringr</em> package (which is part of the tidyverse), lets you use regular expressions and, in this case, the expressions are easy formulate since it consists of a single work, a colon and one or more spaces or tabs (white space) that we want to cut (replace with an empty string).</p>
<p>A further step with posted is to the base R <em>as.Date()</em> function to convert it to a date.</p>
<pre class="r"><code>jobs &lt;- jobs %&gt;% 
  mutate(location = str_replace(location,&quot;Location:\\s*&quot;,&quot;&quot;),
         posted = as.Date(str_replace(posted, &quot;Posted:\\s*&quot;,&#39;&#39;),format=&quot;%m.%d.%Y&quot;))</code></pre>
<pre class="r"><code>jobs %&gt;% 
  datatable(options=list(dom=&#39;t&#39;))</code></pre>
<p><div id="htmlwidget-2" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18"],["Digital Journalist (Political)","Digital Journalist","Managing Director, Digital (Midwest)","Director of Intelligence Project","McGraw Fellowship for Business Journalism","Investigative Media Journalist","Executive Producer","Knight Science Journalism at MIT 2020-21 Project Fellowship","Data Reporter","Audience Engagement Editor","Reporter","Data Reporter","Chief Revenue Officer","Data Reporter","Data Specialist","Editor-in-Chief","Editor-in-chief","Digital Outreach Director"],["Spectrum Networks","Spectrum Networks","Spectrum Networks","Intelligence Project","McGraw Center for Business Journalism","Dolcefino Consulting","Dolcefino Consulting","Knight Science Journalism Program","Louisville Public Media","The Marshall Project","The Press Democrat","WBUR","inewsource","Richmond Times-Dispatch","The Washington Post","The Simons Foundation","Spectrum","Global Investigative Journalism Network"],["Madison, WI","Cleveland, Ohio","Louisville, KY, Milwaukee, WI, Columbus, Ohio","Montgomery, Alabama or Atlanta","New York, NY","Houston, TX","Houston, TX","Remote","Louisville, KY","New York, NY","Santa Rosa, CA","Boston, MA","San Diego, CA","Richmond, VA","Washington, DC","New York, NY","New York, NY","Remote"],["2020-06-10","2020-06-10","2020-06-10","2020-06-08","2020-06-05","2020-06-05","2020-06-05","2020-05-29","2020-05-26","2020-05-21","2020-05-15","2020-05-14","2020-05-13","2020-05-12","2020-05-08","2020-05-06","2020-05-04","2020-04-29"],["https://www.ire.org/archives/jobs/job/digital-journalist-political","https://www.ire.org/archives/jobs/job/digital-journalist","https://www.ire.org/archives/jobs/job/managing-director-digital-midwest","https://www.ire.org/archives/jobs/job/director-of-intelligence-project","https://www.ire.org/archives/jobs/job/mcgraw-fellowship-for-business-journalism-4","https://www.ire.org/archives/jobs/job/investigative-media-journalist","https://www.ire.org/archives/jobs/job/executive-producer-6","https://www.ire.org/archives/jobs/job/knight-science-journalism-at-mit-2020-21-project-fellowship","https://www.ire.org/archives/jobs/job/data-reporter-16","https://www.ire.org/archives/jobs/job/audience-engagement-editor-2","https://www.ire.org/archives/jobs/job/reporter-11-1","https://www.ire.org/archives/jobs/job/data-reporter-15","https://www.ire.org/archives/jobs/job/chief-revenue-officer-2","https://www.ire.org/archives/jobs/job/data-reporter-14","https://www.ire.org/archives/jobs/job/data-specialist","https://www.ire.org/archives/jobs/job/editor-in-chief-4","https://www.ire.org/archives/jobs/job/editor-in-chief-3","https://www.ire.org/archives/jobs/job/digital-outreach-director"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>title<\/th>\n      <th>employer<\/th>\n      <th>location<\/th>\n      <th>posted<\/th>\n      <th>url<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"t","order":[],"autoWidth":false,"orderClasses":false,"columnDefs":[{"orderable":false,"targets":0}]}},"evals":[],"jsHooks":[]}</script>
Much better. This next part is optional until you’ve already scraped the data once. Basically, you load in the previously scraped data, which is stored in a tibble imaginatively named “previous_jobs”, use the <em>anti_join()</em> function to identify any job lists in the new data that are not in the previous data and then combine the new and previous jobs into a new version of “previous_jobs” that you save to your hard drive for future endeavors.</p>
<pre class="r"><code># load previous_jobs from save file
load(paste0(save_path,&#39;ire_jobs.RData&#39;))

# Any new jobs?
new_jobs &lt;- anti_join(jobs, previous_jobs)</code></pre>
<pre><code>## Joining, by = c(&quot;title&quot;, &quot;employer&quot;, &quot;location&quot;, &quot;posted&quot;, &quot;url&quot;)</code></pre>
<pre class="r"><code># if so, update the database
if (nrow(new_jobs) &gt; 0) {
  previous_jobs &lt;- bind_rows(new_jobs,previous_jobs)
  save(previous_jobs, file=paste0(save_path,&#39;ire_jobs.RData&#39;))
}</code></pre>
<p>Finally, if there are new jobs, take a look at them.</p>
<pre class="r"><code>if (nrow(new_jobs)&gt;0) {
  new_jobs %&gt;% 
    data_table(options=list(dom=&#39;t&#39;))
} else {
  print(&#39;No new jobs&#39;)
}</code></pre>
<pre><code>## [1] &quot;No new jobs&quot;</code></pre>
</div>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

