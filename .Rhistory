data_county <- map(county_files, read_tsv)
View(data_county)
View(data_county)
data_county <- map_df(county_files, read_tsv)
View(data_county)
names(data_county) <- make.names(data_county)
View(data_county)
data_county <- map_df(county_files, read_tsv)
names(data_county)
names(data_county) <- make.names(names(data_county))
names(data_county)
new_names <- names(data_county)
new_names <- gsub(pattern="\\.", replacement="_", x=new_names)
new_names
new_names <- tolower(new_names)
new_names
data_county <- map_df(county_files, read_tsv)
new_names <- make.names(names(data_county))
new_names <- gsub(pattern="\\.", replacement="_", x=new_names)
new_names <- tolower(new_names)
new_names <- gsub(pattern='^governmental_funds','gf')
new_names <- gsub(pattern='^governmental_funds','gf',new_names)
new_names
new_names <- gsub(pattern='^governmental_fund','gf',new_names)
new_names <- gsub(pattern='^proprietary_funds','pf',new_names)
new_names
new_names <- gsub(pattern='^fiduciary_funds','pf',new_names)
new_names
# fix column names
new_names <- make.names(names(data_county))
new_names <- gsub(pattern="\\.", replacement="_", x=new_names)
new_names <- tolower(new_names)
new_names <- gsub(pattern='^governmental_funds','gf',new_names)
new_names <- gsub(pattern='^governmental_fund','gf',new_names)
new_names <- gsub(pattern='^proprietary_funds','pf',new_names)
new_names <- gsub(pattern='^fiduciary_funds','ff',new_names)
new_names
new_names <- gsub(pattern='^internal_fund','ff',new_names)
# fix column names
new_names <- make.names(names(data_county))
new_names <- gsub(pattern="\\.", replacement="_", x=new_names)
new_names <- tolower(new_names)
new_names <- gsub(pattern='^governmental_funds','gf',new_names)
new_names <- gsub(pattern='^governmental_fund','gf',new_names)
new_names <- gsub(pattern='^proprietary_funds','pf',new_names)
new_names <- gsub(pattern='^fiduciary_funds','ff',new_names)
new_names <- gsub(pattern='^internal_fund','if',new_names)
new_names
new_names <- gsub(pattern='^internal_service_fund','isf',new_names)
new_names
new_names <- gsub(pattern='^proprietaryfunds','pf',new_names)
new_names
names(data_county) <- new_names
View(data_county)
data_county %>%
gather(category, amount)
View(data_county)
# tidy it up
data_county %>%
gather(category, amount, -municipality_id, -municipality_name)
# tidy it up
data_county %>%
gather(category, amount, -municipality_id, -municipality_name, -reporting_year)
# tidy it up
data_county %>%
gather(category, amount, -municipality_id, -municipality_name, -reporting_year, -afr_id)
glipse(data_county)
glimpse(data_county)
# tidy it up
data_county <- data_county %>%
gather(category, amount, -municipality_id, -municipality_name, -reporting_year, -afr_id)
glimpse(data_county)
data_county %>%
filter(municipality_name=='ALLEGHENY COUNTY') %>%
group_by(afr_id) %>%
count()
library(tidyverse)
library(readr)
path_county <- 'C:/Users/Brian/Documents/Projects/pa_counties/'
path_muni <- 'C:/Users/Brian/Documents/Projects/pa_municipalities/'
# county data
county_files <- list.files(path=path_county, pattern='Statewide.*\\.txt',full.names=T)
data_county <- map_df(county_files, read_tsv)
# fix column names
new_names <- make.names(names(data_county))
new_names <- gsub(pattern="\\.", replacement="_", x=new_names)
new_names <- tolower(new_names)
new_names <- gsub(pattern='^governmental_funds','gf',new_names)
new_names <- gsub(pattern='^governmental_fund','gf',new_names)
new_names <- gsub(pattern='^proprietary_funds','pf',new_names)
new_names <- gsub(pattern='^proprietaryfunds','pf',new_names)
new_names <- gsub(pattern='^fiduciary_funds','ff',new_names)
new_names <- gsub(pattern='^internal_fund','if',new_names)
new_names <- gsub(pattern='^internal_service_fund','isf',new_names)
names(data_county) <- new_names
# tidy it up
data_county <- data_county %>%
gather(category, amount, -municipality_id, -municipality_name, -reporting_year, -afr_id)
glimpse(data_county)
data_county %>%
filter(afr_id == 25814) %>%
group_by(municipality_name) %>%
count()
data_county %>%
filter(municipality_name=='ALLEGHENY COUNTY') %>%
group_by(reporting_year, afr_id) %>%
count()
summary(data_county)
data_county %>%
filter(category=='taxes_per_capita') %>%
group_by(reporting_year) %>%
summarise(avg = mean(value))
data_county %>%
filter(category=='taxes_per_capita') %>%
group_by(reporting_year) %>%
summarise(avg = mean(amount))
data_county %>%
filter(category=='taxes_per_capita') %>%
group_by(reporting_year) %>%
summarise(avg = mean(amount,na.rm=T))
# county data
county_files <- list.files(path=path_county, pattern='Statewide.*\\.txt',full.names=T)
data_county <- map_df(county_files, read_tsv)
# fix column names
new_names <- make.names(names(data_county))
new_names <- gsub(pattern="\\.", replacement="_", x=new_names)
new_names <- tolower(new_names)
new_names <- gsub(pattern='^governmental_funds','gf',new_names)
new_names <- gsub(pattern='^governmental_fund','gf',new_names)
new_names <- gsub(pattern='^proprietary_funds','pf',new_names)
new_names <- gsub(pattern='^proprietaryfunds','pf',new_names)
new_names <- gsub(pattern='^fiduciary_funds','ff',new_names)
new_names <- gsub(pattern='^internal_fund','if',new_names)
new_names <- gsub(pattern='^internal_service_fund','isf',new_names)
names(data_county) <- new_names
# narrow
data_county_n <- data_county %>%
gather(category, amount, -municipality_id, -municipality_name, -reporting_year, -afr_id)
glimpse(data_county)
data_county %>%
filter(municipality_name=='ALLEGHENY COUNTY') %>%
group_by(reporting_year, afr_id) %>%
count()
data_county %>%
filter(afr_id == 25814) %>%
group_by(municipality_name) %>%
count()
summary(data_county)
glimpse(data_county)
data_county$gf_revenues
data_county %>%
select_if(function(x) all(is.na(x)))
data_county <- data_county %>%
select(-gf_revenues, -gf_expenditures, -pf, -ff, -miscellanous_information)
data_county %>%
group_by(reporting_year) %>%
summarise(med_tax_per_cap = median(taxes_per_capita))
data_county %>%
group_by(reporting_year) %>%
summarise(med_tax_per_cap = median(taxes_per_capita,na.rm=T))
data_county %>%
filter(municipality_name=='ALLEGHENY COUNTY') %>%
group_by(reporting_year, afr_id) %>%
count()
data_county %>%
filter(is.na(taxes_per_capita))
library(tidyverse)
library(readr)
path_county <- 'C:/Users/Brian/Documents/Projects/pa_counties/'
path_muni <- 'C:/Users/Brian/Documents/Projects/pa_municipalities/'
# county data
county_files <- list.files(path=path_county, pattern='Statewide.*\\.txt',full.names=T)
data_county <- map_df(county_files, read_tsv)
# fix column names
new_names <- make.names(names(data_county))
new_names <- gsub(pattern="\\.", replacement="_", x=new_names)
new_names <- tolower(new_names)
new_names <- gsub(pattern='^governmental_funds','gf',new_names)
new_names <- gsub(pattern='^governmental_fund','gf',new_names)
new_names <- gsub(pattern='^proprietary_funds','pf',new_names)
new_names <- gsub(pattern='^proprietaryfunds','pf',new_names)
new_names <- gsub(pattern='^fiduciary_funds','ff',new_names)
new_names <- gsub(pattern='^internal_fund','if',new_names)
new_names <- gsub(pattern='^internal_service_fund','isf',new_names)
names(data_county) <- new_names
glimpse(data_county)
data_county %>%
select_if(function(x) all(is.na(x)))
data_county <- data_county %>%
select(-gf_revenues, -gf_expenditures, -pf, -ff, -miscellanous_information)
data_county %>%
group_by(reporting_year) %>%
summarise(med_tax_per_cap = median(taxes_per_capita,na.rm=T))
data_county %>%
filter(municipality_name == 'ALLEGHENY COUNTY',reporting_year==2016)
setwd("c:/users/brian/documents/Projects/pa_counties")
blogdown:::serve_site()
blogdown:::new_post_addin()
library(tidyverse)
library(DT)
load('C:/Users/Brian/Documents/Projects/pa_local_gov/data_county_web.RData')
data_county_web %>%
datatable(extensions= "FixedColumns",
options=list(scrollX = TRUE, fixedColumns=list(leftColumns=2)),
colnames=c('County','Total general fund revnues','From taxes','From federal','From state','From other local')) %>%
formatCurrency(3,digits=0) %>%
formatPercentage(4:7,digits=1)
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::new_post_addin()
library(tidyverse)
library(scales)
library(reshape2)
library(DT)
blogdown:::serve_site()
blogdown:::new_post_addin()
save(q1_by_q2.RData)
library(tidyverse)
library(haven)
# load data
sept18 <- read_sav('c:/users/brian/documents/mystuff/projects/api_stuff/data_raw/Sept18 public.sav', user_na = T) %>%
as_factor()
# create survey design
sept18_design = svydesign(
ids = ~0, #formula indicating there are no clusters
data = sept18,      #this is the dataset
weights = ~weight) #this is the 'weight' variable from the dataset
library(tidyverse)
library(haven)
library(survey)
# load data
sept18 <- read_sav('c:/users/brian/documents/mystuff/projects/api_stuff/data_raw/Sept18 public.sav', user_na = T) %>%
as_factor()
# create survey design
sept18_design = svydesign(
ids = ~0, #formula indicating there are no clusters
data = sept18,      #this is the dataset
weights = ~weight) #this is the 'weight' variable from the dataset
# get q1 by q2
q1_by_q2 = svyby(~q2,            #variable to estimate
~q1,          #subgroup variable
design = sept18_design,
FUN = svymean, #function to use on each subgroup
keep.names = FALSE #does not include row.names
#for subgroup variable
)
# clean it up
q1_by_q2 <- q1_by_q2 %>%
select(q1, Approve = q2Approve, Disapprove = q2Disapprove, "Don't know/Refused" = `q2(VOL) Don't know/Refused`) %>%
gather(key=q2, value=Percent, Approve, Disapprove, `Don't know/Refused`)
levels(q1_by_q2$q1) <- c('Satisfied','Dissatisfied',"Don't know/Refused")
# plot it
q1_by_q2 %>% ggplot(aes(x=q1, y=Percent, group=q2, fill=q2)) +
geom_col(position='dodge') +
scale_fill_manual(values=c('green','red','orange')) +
scale_y_continuous(labels=scales::percent) +
labs(title="Trump approval by how satisfied people are with the country's direction",
x='All in all, are you satisfied or dissatisfied with the way things are going in this country today?',
subtitle='Do you approve or disapprove of the way Donald Trump is handling his job as President?') +
theme(legend.title = element_blank())
library(tidyverse)
library(haven)
library(survey)
# load data
sept18 <- read_sav('c:/users/brian/documents/mystuff/projects/api_stuff/data_raw/Sept18 public.sav', user_na = T) %>%
as_factor()
# create survey design
sept18_design = svydesign(
ids = ~0, #formula indicating there are no clusters
data = sept18,      #this is the dataset
weights = ~weight) #this is the 'weight' variable from the dataset
# get q1 by q2
q1_by_q2 = svyby(~q2,            #variable to estimate
~q1,          #subgroup variable
design = sept18_design,
FUN = svymean, #function to use on each subgroup
keep.names = FALSE #does not include row.names
#for subgroup variable
)
# clean it up
q1_by_q2 <- q1_by_q2 %>%
select(q1, Approve = q2Approve, Disapprove = q2Disapprove, "Don't know/Refused" = `q2(VOL) Don't know/Refused`) %>%
gather(key=q2, value=Percent, Approve, Disapprove, `Don't know/Refused`)
levels(q1_by_q2$q1) <- c('Satisfied','Dissatisfied',"Don't know/Refused")
# plot it
q1_by_q2 %>% ggplot(aes(x=q1, y=Percent, group=q2, fill=q2)) +
geom_col(position='dodge') +
scale_fill_manual(values=c('green','red','orange')) +
scale_y_continuous(labels=scales::percent) +
labs(title="Trump approval by how satisfied people are with the country's direction",
x='All in all, are you satisfied or dissatisfied with the way things are going in this country today?',
subtitle='Do you approve or disapprove of the way Donald Trump is handling his job as President?') +
theme(legend.title = element_blank(), plot.subtitle=element_text(size=10))
blogdown:::serve_site()
blogdown::install_hugo()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
library(tidyverse)
library(DT)
library(scales)
library(janitor)
load('C:/Users/bowli/Documents/Data/federal/homelessness/homeless_2018.RData')
library(tidyverse)
library(readxl)
library(tidycensus)
library(janitor)
stats_2018 <- read_xlsx(path = 'C:/Users/bowli/Documents/Data/federal/homelessness/2007-2018-PIT-Counts-by-State.xlsx',
sheet=2) %>%
clean_names(case = 'snake')
homeless_2018 <- stats_2018 %>%
select(state, overall_homeless_2018)
pops <- get_estimates(geography='state',year=2018, product='population')
abbrevs <- read_tsv('C:/Users/bowli/Documents/Data/reference/state_abbreviations.csv')
View(pops)
View(abbrevs)
View(pops)
pops2 <- left_join(pops, abbrevs, by=c('NAME'='state'))
View(pops2)
pops2 <- pops2 %>%
rename(state='NAME', population='value') %>%
filter(variable=='POP') %>%
select(state, abbreviation, population)
View(homeless_2018)
homeless_2018 <- homeless_2018 %>%
rename(abbreviation='state')
left_join(pops2,by='abbreviation')
View(pops2)
View(homeless_2018)
View(pops2)
stats_2018 <- read_xlsx(path = 'C:/Users/bowli/Documents/Data/federal/homelessness/2007-2018-PIT-Counts-by-State.xlsx',
sheet=2) %>%
clean_names(case = 'snake')
homeless_2018 <- stats_2018 %>%
select(state, overall_homeless_2018)
homeless_2018 <- homeless_2018 %>%
rename(abbreviation='state') %>%
left_join(pops2,by='abbreviation')
# get rid of NA (territories)
homeless_2018 <- homeless_2018 %>%
filter(!is.na(population)) %>%
filter(!state == 'PR')
View(homeless_2018)
homeless_2018 <- homeless_2018 %>%
mutate(homeless_pct = overall_homeless_2018/population) %>%
select(state, abbreviation, overall_homeless_2018, population, homeless_pct)
homeless_2018 %>%
arrange(desc(homeless_pct))
homeless_2018 <- homeless_2018 %>%
arrange(desc(homeless_pct))
save(homeless_2018, file='C:/Users/bowli/Documents/Data/federal/homelessness/homeless_2018.RData')
load('C:/Users/bowli/Documents/Data/federal/homelessness/homeless_2018.RData')
View(homeless_2018)
homeless_2018 %>%
select(state, homeless_pct) %>%
datatable(colnames=c('State',"Percent of population that's homeless")
)
homeless_2018 %>%
select(state, homeless_pct) %>%
datatable(colnames=c('State',"Percent of population that's homeless") %>%
formatPercentage(2, digits=3)
)
homeless_2018 %>%
select(state, homeless_pct) %>%
datatable(colnames=c('State',"Percent of population that's homeless")) %>%
formatPercentage(2, digits=3)
)
homeless_2018 %>%
select(state, homeless_pct) %>%
datatable(colnames=c('State',"Percent of population that's homeless")) %>%
formatPercentage(2, digits=3)
homeless_2018 %>%
select(state, homeless_pct) %>%
datatable(colnames=c('State',"Percent of population that's homeless")) %>%
formatPercentage(2, digits=2)
homeless_2018 %>%
select(state, homeless_pct) %>%
datatable(colnames=c('State',"Percent of population that is homeless")) %>%
formatPercentage(2, digits=2)
blogdown:::serve_site()
blogdown:::serve_site()
homeless_2018 %>%
select(state, homeless_pct) %>%
datatable(colnames=c('State',"Percent of population in 2018 that was homeless")) %>%
formatPercentage(2, digits=2)
homeless_2018 %>%
select(state, homeless_pct) %>%
datatable(colnames=c('State',"Percent of population in 2018 that was homeless")) %>%
formatPercentage(2, digits=2)
homeless_2018 %>%
select(state, homeless_pct) %>%
datatable(colnames=c('State',"Percent of population in 2018 that was homeless")) %>%
formatPercentage(2, digits=2)
# this is the underlying code for the Pittsburgh job trend blog post
# libraries
library(tidyverse)
library(readr)
library(kml)
library(scales)
# data
load(file='C:/Users/Brian/Documents/Projects/metro_analysis/data_processed/employment_ann.RData')
# this is the underlying code for the Pittsburgh job trend blog post
# libraries
library(tidyverse)
library(readr)
library(kml)
library(scales)
# data
load(file='C:/Users/bowli/Documents/Projects/metro_analysis/data_processed/employment_ann.RData')
load(file='C:/Users/bowli/Documents/Projects/metro_analysis/data_processed/codes.RData')
# data prep
employment_ann <- merge(code_state,employment_ann)
employment_ann <- merge(code_area, employment_ann)
employment_ann <- merge(code_supersector, employment_ann)
employment_ann <- merge(code_industry, employment_ann)
employment_ann <- employment_ann %>%
select(state_code, state_name, area_code, area_name,
supersector_code, supersector_name, industry_code,industry_name,
year, value)
employment_ann$industry_code <- substr(employment_ann$industry_code,3,8)
employment_ann_total <- employment_ann %>%
filter(supersector_code=='00',industry_code=='000000')
temp2 <- employment_ann_total %>%
filter(year==2006) %>%
rename(value_2006 = value) %>%
select(area_code, value_2006)
employment_ann_total <- left_join(employment_ann_total, temp2, by='area_code')
employment_ann_total <- employment_ann_total %>%
group_by(area_code) %>%
mutate(job_index = value/value_2006)
# longitudinal clustering
employment_kml <- employment_ann_total %>%
select(area_code, area_name, year, job_index) %>%
spread(year, job_index)
employment_kml <- as.data.frame(employment_kml)
employment_cld <- cld(employment_kml,
timeInData = c(3:14),
time=c(2006:2017))
# in preparing for this post, I did a standard kml run, from that I picked 4 as
# the nubmer of clusters
kml(employment_cld, nbClusters=4, nbRedrawing=3,toPlot='none')
employment_kml$cluster = getClusters(employment_cld, 4)
employment_cluster <- employment_kml %>%
group_by(area_code) %>%
select(area_code, cluster)
employment_ann_total <- left_join(employment_ann_total, employment_cluster, by='area_code')
# graphs
# pittsburgh job total
# get max value to set y limit
y_max = max(employment_ann_total$value[employment_ann_total$area_name=='Pittsburgh, PA'])
pitt_jobs1 <- employment_ann_total %>%
filter(area_name=='Pittsburgh, PA') %>%
ggplot(aes(x=year, y=value)) +
geom_line() +
scale_x_continuous(breaks=seq(2006,2017,1)) +
scale_y_continuous(labels=comma) +
labs(title="Pittsburgh's total nonfarm payroll employment (annual average)",
x='Year',
y='Jobs (thousands)') +
theme_minimal()
pitt_jobs2 <- employment_ann_total %>%
filter(area_name=='Pittsburgh, PA') %>%
ggplot(aes(x=year, y=value)) +
geom_line() +
scale_x_continuous(breaks=seq(2006,2017,1)) +
scale_y_continuous(labels=comma, limits=c(0,y_max)) +
labs(title="Pittsburgh's total nonfarm payroll employment (annual average)",
x='Year',
y='Jobs (thousands)') +
theme_minimal()
pitt_jobs_index <- employment_ann_total %>%
filter(area_name=='Pittsburgh, PA') %>%
ggplot(aes(x=year,y=job_index)) +
geom_line() +
scale_x_continuous(breaks=seq(2006,2017,1)) +
labs(title="Pittsburgh job index (reference year is 2006)",
x='Year',
y='Index') +
theme_minimal()
all_jobs_index <- employment_ann_total %>%
ggplot(aes(x=year, y=job_index)) +
geom_line(aes(group=area_code),alpha=.5) +
geom_smooth(se=FALSE,method='gam', formula= y~s(x,bs='cs')) +
# highlight Pittsburgh MSA
geom_line(aes(x=year, y=job_index), data=filter(employment_ann_total,area_code=='38300'),color='yellow') +
scale_x_continuous(breaks=seq(2006, 2017,1)) +
labs(title = "Metro job growth since 2006",
y="Total nonfarm payroll employment (indexed to 2006)",
subtitle="Pittsburgh MSA shown in yellow") +
theme_minimal()
all_jobs_clustered <- employment_ann_total %>%
ggplot(aes(x=year, y=job_index)) +
geom_line(aes(group=area_code, color=cluster),alpha=.5) +
geom_smooth(se=FALSE,method='gam', formula= y~s(x,bs='cs')) +
# highlight Pittsburgh MSA
geom_line(aes(x=year, y=job_index, color='yellow'),
data=filter(employment_ann_total,area_code=='38300'),
size=1) +
scale_color_manual(labels=c('Slightly Worse', 'Slightly Better', 'Much worse', 'Much better','Pittsburgh (slightly better)'),
values=c('pink','lightgreen','red','darkgreen','yellow')) +
scale_x_continuous(breaks=seq(2006, 2017,1)) +
labs(title = "Metro job growth",
y="Job growth index",
subtitle="(Average annual total nonfarm payroll employment indexed to 2006)",
x="") +
theme_minimal() +
theme(plot.title=element_text(size=24),
legend.position='bottom', legend.title=element_blank()) +
guides(colour=guide_legend(override.aes=list(alpha=1, size=1)))
all_jobs_clustered
