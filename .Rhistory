plot_demo <- function() {
df <- data.frame(day = 1:30, arr_delay = 1:30)
ui <- fluidPage(plot_ui("x"))
server <- function(input, output, session) {
plot_server("x", reactive({df}), "arr_delay")
}
shinyApp(ui, server)
}
plot_demo()
metric_server <- function(id, df, vbl, threshhold) {
moduleServer(id, function(input, output, session) {
text_server("metric", df, vbl, threshhold)
plot_server("metric", df, vbl, threshhold)
})
}
metric_demo <- function() {
df <- data.frame(day = 1:30, arr_delay = 1:30)
ui <- fluidPage(metric_ui("x"))
server <- function(input, output, session) {
metric_server("x", reactive({df}), "arr_delay", 15)
}
shinyApp(ui, server)
}
metro_demo()
metric_demo()
metric_ui <- function(id) {
fluidRow(
text_ui(NS(id, "metric")),
plot_ui(NS(id, "metric"))
)
}
metric_server <- function(id, df, vbl, threshhold) {
moduleServer(id, function(input, output, session) {
text_server("metric", df, vbl, threshhold)
plot_server("metric", df, vbl, threshhold)
})
}
metric_demo <- function() {
df <- data.frame(day = 1:30, arr_delay = 1:30)
ui <- fluidPage(metric_ui("x"))
server <- function(input, output, session) {
metric_server("x", reactive({df}), "arr_delay", 15)
}
shinyApp(ui, server)
}
metric_demo()
ui <- fluidPage(
titlePanel("Flight Delay Report"),
sidebarLayout(
sidebarPanel = sidebarPanel(
selectInput("month", "Month",
choices = setNames(1:12, month.abb),
selected = 1
)
),
mainPanel = mainPanel(
h2(textOutput("title")),
h3("Average Departure Delay"),
metric_ui("dep_delay"),
h3("Average Arrival Delay"),
metric_ui("arr_delay"),
h3("Proportion Flights with >5 Min Arrival Delay"),
metric_ui("ind_arr_delay")
)
)
)
server <- function(input, output, session) {
output$title <- renderText({paste(month.abb[as.integer(input$month)], "Report")})
df_month <- reactive({filter(ua_data, month == input$month)})
metric_server("dep_delay", df_month, vbl = "dep_delay", threshhold = 10)
metric_server("arr_delay", df_month, vbl = "arr_delay", threshhold = 10)
metric_server("ind_arr_delay", df_month, vbl = "ind_arr_delay", threshhold = 0.5)
}
shinyApp(ui, server)
install.packages(c(
"gapminder", "ggforce", "openintro", "shiny", "shinycssloaders",
"shinyFeedback", "shinythemes", "thematic", "tidyverse", "vroom",
"waiter", "zeallot"
))
library(shiny)
blogdown:::serve_site()
install.packages('DT')
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
# libraries
library(tidyverse)
library(rmarkdown)
library(DT)
# load files
path_raw <- 'c:users/brian/Documents/data/fed_bls/employment/'
current <- read_tsv(paste0(path_raw,'sm/sm_data_0_current.txt'))
# libraries
library(tidyverse)
library(rmarkdown)
library(DT)
# load files
path_raw <- 'c:/users/brian/Documents/data/fed_bls/employment/'
current <- read_tsv(paste0(path_raw,'sm/sm_data_0_current.txt'))
cd_state <- read_tsv(paste0(path_raw,'sm/sm_state.txt'))
cd_area <- read_tsv(paste0(path_raw,'sm/sm_area.txt'))
cd_supersector <- read_tsv(paste0(path_raw,"sm/sm_supersector.txt"))
cd_industry <- read_tsv(paste0(path_raw,'sm/sm_industry.txt'))
# extract info from series_id
current <- current %>%
separate(series_id, sep=c(2,3,5,10,12,18,20),into=c('survey','seasonal',
'state','area','supersector','industry',
'data_type'),
remove=F)
# limit to latest annual data
current <- current %>%
filter(period=='M13', year==2019)
# limit to msas
current <- current %>%
filter(area!='00000', !grepl('.{4}4',area))
# create separate files for employment and hours_wages
employment <- current %>%
filter(data_type=='01')
wage_hour <- current %>%
filter(data_type == '11')
#  and remove unnecessary columns
# pitt data
pitt_code <- cd_area %>%
filter(str_detect(area_name,'Pittsburgh')) %>%
pull(area_code)
pitt_emp <- current %>%
filter(area==pitt_code) %>%
select(supersector, industry, value) %>%
mutate(local_share = round(value/max(value),digits=5))
# msa aggregate
msa_agg <- current %>%
group_by(supersector, industry) %>%
summarise(agg_value = sum(value)) %>%
ungroup() %>%
mutate(agg_share = round(agg_value/max(agg_value),digits=5))
# combined
pitt_emp <- pitt_emp %>%
left_join(msa_agg, by=c('supersector','industry')) %>%
select(supersector, industry, value, local_share, agg_share)
# calculate lq
pitt_emp <- pitt_emp %>%
mutate(lq=round(local_share/agg_share,digits=3))
# calculate theoretical employment based on aggregate model
pitt_emp <- pitt_emp %>%
mutate(theoretical = max(value) * agg_share,
diff = value - theoretical)
primary_metals <- pitt_emp %>%
filter(industry=='331000')
blogdown:::serve_site()
blogdown::install_hugo()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
gnd_cover <- tribble(
~code, ~desc,
'0','unknown',
'1','grass',
'2','fallow',
'3','bare ground',
'4','brome grass',
'5','sod',
'6','straw multch',
'7','grass muck',
'8','bare muck'
)
library(tidyverse)
gnd_cover <- tribble(
~code, ~desc,
'0','unknown',
'1','grass',
'2','fallow',
'3','bare ground',
'4','brome grass',
'5','sod',
'6','straw multch',
'7','grass muck',
'8','bare muck'
)
depth_codes <- tribble(
~code,~depth,
'1','5 cm',
'2','10 cm',
'3','20 cm',
'4','50 cm',
'5','100 cm',
'6','150 cm',
'7','180 cm'
)
library(tidyverse)
gnd_cover <- tribble(
~code, ~desc,
'0','unknown',
'1','grass',
'2','fallow',
'3','bare ground',
'4','brome grass',
'5','sod',
'6','straw multch',
'7','grass muck',
'8','bare muck'
)
depth_codes <- tribble(
~code,~depth,
'1','5 cm',
'2','10 cm',
'3','20 cm',
'4','50 cm',
'5','100 cm',
'6','150 cm',
'7','180 cm'
)
soil_temp_lookup <- bind_cols(unite(crossing("SN",gnd_cover$code,depth_codes$code),
soil_temp,sep=''),
unite(crossing(gnd_cover$desc,depth_codes$depth),desc,sep=", "))
soil_temp_lookup
blogdown:::serve_site()
blogdown:::new_post_addin()
# load libraries
library(tidyverse)
# constants
num_rounds <- 1000
# function to simulate playing the game
monty_runs <- function(switcher, num_rounds) {
# table to hold results of games
player_results = tribble(
~result, ~count,
'goat', 0,
'car',0
)
# start of game loop
for (i in 1:num_rounds){
# pick the door for the car
car <- sample(1:3,1)
# have player pick a door
player_choice = sample(1:3,1)
# make a list of the doors player hasn't picked
other_doors <- 1:3
other_doors <- other_doors[other_doors != player_choice]
# pick a door to open, revealing it has a goat behind it
# if player picked the door that has a car behind it, randomly open
# one of the other doors
# if player picked a door with a goat behind it, open the other door with
# a goat behind it
if (player_choice==car) {
reveal = other_doors[sample(1:2,1)]
} else {
reveal = ifelse(other_doors[1]==car,other_doors[2],other_doors[1])
}
# make a list of the doors that are still closed
doors_left <- 1:3
doors_left <- doors_left[doors_left != reveal]
# have player decided whether to stick with the door he or she originally
# picked or switch to the other closed door
if (switcher) {
player_choice <- doors_left[doors_left != player_choice]
}
# update results
player_wins <- ifelse(player_choice==car,'car','goat')
player_results <- player_results %>%
mutate(count = ifelse(result==player_wins,count+1, count))
}
return(player_results)
}
# run the simulation twice, once for a player who always switches
# and once for a player who always sticks and compile the results
player_switches <- monty_runs(TRUE,1000) %>%
mutate(player_type='switcher')
player_stays <- monty_runs(FALSE, 1000) %>%
mutate(player_type='stayer')
monty_results <- bind_rows(player_switches, player_stays) %>%
pivot_wider(id_cols=player_type,names_from=result,values_from=count) %>%
mutate(pct_car = round(car/(goat+car),digits=3))
library(DT)
monty_results %>%
datatable(colnames = c("Player Style","Picks a goat","Picks the car","Success percentage")) %>%
formatPercentage('pct_car')
library(DT)
monty_results %>%
datatable(colnames = c("Player Style","Picks a goat","Picks the car","Success percentage"),
options=list(dom='t')) %>%
formatPercentage('pct_car')
blogdown:::serve_site()
# library
library(tidyverse)
library(lubridate)
library(DT)
library(scales)
options(dplyr.summarise.inform = FALSE)
# name of download file changes and is a alphanumeric mess, so just search for it
file_target <- list.files('C:/Users/Brian/Documents/data/pittsburgh/calls_311/',
pattern="*.csv",
full.names=T)
# load data
calls <- read_csv(file_target,
col_types= cols(.default=col_character(),
CREATED_ON=col_datetime(format=""),
X = col_double(),
Y = col_double()))
# period is midnight March 1 of each year to midnight of Nov. 1
calls <- calls %>%
mutate(covid_category = case_when(
between(CREATED_ON,as.POSIXct('2020-03-01 00:00:00'),as.POSIXct('2020-11-01 00:00:00')) ~
'ref2020',
between(CREATED_ON,as.POSIXct('2019-03-01 00:00:00'),as.POSIXct('2019-11-01 00:00:00')) ~
'ref2019',
between(CREATED_ON,as.POSIXct('2018-03-01 00:00:00'),as.POSIXct('2018-11-01 00:00:00')) ~
'ref2018',
between(CREATED_ON,as.POSIXct('2017-03-01 00:00:00'),as.POSIXct('2017-11-01 00:00:00')) ~
'ref2017',
between(CREATED_ON,as.POSIXct('2016-03-01 00:00:00'),as.POSIXct('2016-11-01 00:00:00')) ~
'ref2016',
TRUE ~ 'N'
))
# covid comparison
covid_comp_all <- calls %>%
filter(covid_category != 'N')
# limit to incity calls
covid_comp <- covid_comp_all %>%
filter(GEO_ACCURACY!='OUT_OF_BOUNDS')
# neighborhoods
neighborhoods <- covid_comp %>%
group_by(covid_category, NEIGHBORHOOD) %>%
summarise(calls_rcvd = n()) %>%
mutate(calls_rcvd = ifelse(is.na(calls_rcvd),0,calls_rcvd)) %>%
pivot_wider(id_cols=NEIGHBORHOOD, names_from=covid_category, values_from=calls_rcvd) %>%
mutate(change_19_20 = ref2020-ref2019,
pct_change = round(change_19_20/ref2019,digits=3))
# requests
requests <- covid_comp %>%
group_by(covid_category, REQUEST_TYPE) %>%
summarise(calls_rcvd = n()) %>%
mutate(calls_rcvd = ifelse(is.na(calls_rcvd),0,calls_rcvd)) %>%
pivot_wider(id_cols=REQUEST_TYPE,names_from=covid_category,values_from=calls_rcvd) %>%
mutate(change_19_20 = ref2020-ref2019,
pct_change = round(change_19_20/ref2019,digits=3))
# tops and bottoms
top5requests <- requests %>%
slice_max(n=5,order_by=change_19_20)
bottom5requests <- requests %>%
slice_min(n=5,order_by=change_19_20)
top3neighborhoods <- neighborhoods %>%
filter(!is.na(NEIGHBORHOOD)) %>%
slice_max(n=3,order_by=change_19_20)
bottom5neighborhoods <- neighborhoods %>%
filter(!is.na(NEIGHBORHOOD)) %>%
slice_min(n=5,order_by=change_19_20)
covid_comp %>%
filter(REQUEST_TYPE=='Referral') %>%
datatable()
covid_comp %>%
filter(REQUEST_TYPE=='Referral')
install.packages('GrpString')
library(tidyverse)
library(sf)
library(lubridate)
# library(zoo)
# library(stringdist)
# library(fuzzyjoin)
library(DT)
library(scales)
library(GrpString)
options(dplyr.summarise.inform = FALSE)
pitt_map <- st_read('C:/Users/Brian/Documents/data/GIS_data/gis_pittsburgh/neighborhoods/pitt_bg_hood.shp')
hood_map <- pitt_map['hood']
# name of download file changes and is a alphanumeric mess, so just search for it
file_target <- list.files('C:/Users/Brian/Documents/data/pittsburgh/calls_311/',
pattern="*.csv",
full.names=T)
calls <- read_csv(file_target,
col_types= cols(.default=col_character(),
CREATED_ON=col_datetime(format=""),
X = col_double(),
Y = col_double()))
# period is midnight March 1 of each year to midnight of Nov. 1
calls <- calls %>%
mutate(covid_category = case_when(
between(CREATED_ON,as.POSIXct('2020-03-01 00:00:00'),as.POSIXct('2020-11-01 00:00:00')) ~
'ref2020',
between(CREATED_ON,as.POSIXct('2019-03-01 00:00:00'),as.POSIXct('2019-11-01 00:00:00')) ~
'ref2019',
between(CREATED_ON,as.POSIXct('2018-03-01 00:00:00'),as.POSIXct('2018-11-01 00:00:00')) ~
'ref2018',
between(CREATED_ON,as.POSIXct('2017-03-01 00:00:00'),as.POSIXct('2017-11-01 00:00:00')) ~
'ref2017',
between(CREATED_ON,as.POSIXct('2016-03-01 00:00:00'),as.POSIXct('2016-11-01 00:00:00')) ~
'ref2016',
TRUE ~ 'N'
))
covid_comp <- calls %>%
filter(covid_category != 'N')
annual <- covid_comp %>%
group_by(covid_category) %>%
summarise(calls_rcvd = n()) %>%
rename(year=covid_category) %>%
mutate(year = substr(year,4,8)) %>%
mutate(change = calls_rcvd - lag(calls_rcvd),
pct_change = round(change / lag(calls_rcvd),digits=3))
covid_comp %>%
group_by(covid_category) %>%
summarise(calls_rcvd = n()) %>%
ggplot(aes(x=covid_category,y=calls_rcvd,fill=covid_category)) +
geom_col() +
labs(title = "Calls to Pittsburgh 311 from March through October",
x = '',
y='') +
scale_x_discrete(labels=c('2016','2017','2018','2019','2020')) +
scale_y_continuous(label=comma,limits = c(0,80000)) +
theme(plot.title=element_text(hjust=0.5),
legend.position = 'none')
neighborhoods <- covid_comp %>%
group_by(covid_category, NEIGHBORHOOD) %>%
summarise(calls_rcvd = n()) %>%
mutate(calls_rcvd = ifelse(is.na(calls_rcvd),0,calls_rcvd)) %>%
pivot_wider(id_cols=NEIGHBORHOOD, names_from=covid_category, values_from=calls_rcvd) %>%
mutate(change_19_20 = ref2020-ref2019,
pct_change = round(change_19_20/ref2019,digits=3))
requests <- covid_comp %>%
group_by(covid_category, REQUEST_TYPE) %>%
summarise(calls_rcvd = n()) %>%
mutate(calls_rcvd = ifelse(is.na(calls_rcvd),0,calls_rcvd)) %>%
pivot_wider(id_cols=REQUEST_TYPE,names_from=covid_category,values_from=calls_rcvd) %>%
mutate(change_19_20 = ref2020-ref2019,
pct_change = round(change_19_20/ref2019,digits=3))
View(requests)
request_types <- calls %>%
group_by(REQUEST_TYPE) %>%
summarise(number=n())
codes_r <- codes %>%
full_join(request_types, by=c('Issue'='REQUEST_TYPE'),keep=T)
codes <- readxl::read_xlsx('C:/Users/Brian/Documents/data/pittsburgh/calls_311/311-codebook-request-types.xlsx','Codebook')
test <- CommonPatt(codes$Issue)
View(test)
write_csv(request_types,'c:/Users/Brian/Documents/data/pittsburgh/calls_311/calls_request_types.csv')
write_csv(codes,'c:/users/Brian/Documents/data/Pittsburgh/calls_311/codes.csv')
lookup <- full_join(request_types,codes,by=c('REQUEST_TYPE'='Issue'))
View(lookup)
write_csv(lookup,'c:/users/brian/documents/data/pittsburgh/calls_311/lookup.csv')
install.packages('tesseract')
library('tesseract')
eng <- tesseract(language='eng')
text <- tesseract::ocr(paste0('C:/Users/Brian/Documents/stuff for other reporters/image02.jpg'),
engine=eng)
text
install.packages('magick')
library('magick')
target <- image_read(image_location)
image_location <- 'C:/Users/Brian/Documents/stuff for other reporters/image02.jpg'
target <- image_read(image_location)
text <- target %>%
image_resize("2000x") %>%
image_convert(type = 'Grayscale') %>%
image_trim(fuzz = 40) %>%
image_write(format = 'png', density = '300x300') %>%
tesseract::ocr()
text
text <- target %>%
image_resize("2000x") %>%
image_convert(type = 'Grayscale') %>%
image_trim(fuzz = 40) %>%
image_reducenoise() %>%
image_write(format = 'png', density = '300x300') %>%
tesseract::ocr()
text <- tesseract::ocr(paste0('C:/Users/Brian/Documents/stuff for other reporters/image02.jpg'),
engine=eng)
text
text <- target %>%
image_resize("2000x") %>%
image_convert(type = 'Grayscale') %>%
image_trim(fuzz = 40) %>%
image_write(format = 'png', density = '300x300') %>%
tesseract::ocr()
text
library(rvest)
test <- read_html('https://ehservices.publichealth.lacounty.gov/ezsearch')
test %>%
html_text()
test <- read_html('https://ehservices.publichealth.lacounty.gov/servlet/guest?service=1&enterprise=5')
test %>%
html_text()
library(tidyverse)
library(RSelenium)
library(rvest)
library(rJava)
rd <- rsDriver(browser='firefox')
ffd <- rd$client
ffd$navigate("https://ehservices.publichealth.lacounty.gov/servlet/guest?service=1&enterprise=5")
html_data <- ffd$getPageSource()[[1]]
nbcla <- html_data %>%
read_html()
nbcla %>%
html_text()
install.packages(c("backports", "blogdown", "bookdown", "broom"))
install.packages(c("backports", "blogdown", "bookdown", "broom"))
install.packages(c("backports", "blogdown", "bookdown", "broom"))
install.packages(c("backports", "blogdown", "bookdown", "broom"))
install.packages(c("backports", "blogdown", "bookdown", "broom"))
install.packages(c("backports", "blogdown", "bookdown", "broom"))
install.packages(c("backports", "blogdown", "bookdown", "broom"))
install.packages(c("backports", "blogdown", "bookdown", "broom"))
install.packages(c("backports", "blogdown", "bookdown", "broom"))
install.packages(c("backports", "blogdown", "bookdown", "broom"))
blogdown:::serve_site()
blogdown::install_hugo(force = TRUE, version = "latest")
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
