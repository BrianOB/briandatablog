left_join(cd_supersector, by=c('supersector'='supersector_code')) %>%
mutate(industry_code = paste0(supersector, industry)) %>%
left_join(cd_industry, by='industry_code') %>%
select(supersector_name, industry_name, value, local_share, lq)
library(DT)
pitt_emp %>%
left_join(cd_supersector, by=c('supersector'='supersector_code')) %>%
mutate(industry_code = paste0(supersector, industry)) %>%
left_join(cd_industry, by='industry_code') %>%
select(supersector_name, industry_name, value, local_share, lq) %>%
datatable()
pitt_emp %>%
left_join(cd_supersector, by=c('supersector'='supersector_code')) %>%
mutate(industry_code = paste0(supersector, industry)) %>%
left_join(cd_industry, by='industry_code') %>%
select(supersector_name, industry_name, value, local_share, lq) %>%
datatable(colnames=c('Supersector','Industry','Employment (in thousands)','Local share',"LQ"))
pitt_emp %>%
left_join(cd_supersector, by=c('supersector'='supersector_code')) %>%
mutate(industry_code = paste0(supersector, industry)) %>%
left_join(cd_industry, by='industry_code') %>%
select(supersector_name, industry_name, value, local_share, lq) %>%
datatable(colnames=c('Supersector','Industry','Employment (in thousands)','Local share',"LQ"))
pitt_emp %>%
left_join(cd_supersector, by=c('supersector'='supersector_code')) %>%
mutate(industry_code = paste0(supersector, industry)) %>%
left_join(cd_industry, by='industry_code') %>%
select(supersector_name, industry_name, value, local_share, lq) %>%
datatable(colnames=c('Supersector','Industry','Employment (in thousands)','Local share',"LQ"))
pitt_emp %>%
left_join(cd_supersector, by=c('supersector'='supersector_code')) %>%
mutate(industry_code = paste0(supersector, industry)) %>%
left_join(cd_industry, by='industry_code') %>%
select(supersector_name, industry_name, value, local_share, lq) %>%
datatable(colnames=c('Supersector','Industry','Employment (in thousands)','Local share',"LQ")) %>%
formatPercentage('local_share')
pitt_emp %>%
left_join(cd_supersector, by=c('supersector'='supersector_code')) %>%
mutate(industry_code = paste0(supersector, industry)) %>%
left_join(cd_industry, by='industry_code') %>%
select(supersector_name, industry_name, value, local_share, lq) %>%
datatable(colnames=c('Supersector','Industry','Employment (in thousands)','Local share',"LQ")) %>%
formatPercentage('local_share',digits=1)
pitt_emp %>%
left_join(cd_supersector, by=c('supersector'='supersector_code')) %>%
mutate(industry_code = paste0(supersector, industry)) %>%
left_join(cd_industry, by='industry_code') %>%
select(supersector_name, industry_name, value, local_share, lq) %>%
datatable(colnames=c('Supersector','Industry','Employment (in thousands)','Local share',"LQ")) %>%
formatPercentage('local_share',digits=1) %>%
formatRound('value',digits=1)
blogdown:::serve_site()
pitt_emp %>%
filter(industry='331000')
# libraries
library(tidyverse)
library(rmarkdown)
library(DT)
# load files
path_raw <- 'D:/Documents/data/fed_bls/employment/'
current <- read_tsv(paste0(path_raw,'sm/sm_data_0_current.txt'))
cd_state <- read_tsv(paste0(path_raw,'sm/sm_state.txt'))
cd_area <- read_tsv(paste0(path_raw,'sm/sm_area.txt'))
cd_supersector <- read_tsv(paste0(path_raw,"sm/sm_supersector.txt"))
cd_industry <- read_tsv(paste0(path_raw,'sm/sm_industry.txt'))
# extract info from series_id
current <- current %>%
separate(series_id, sep=c(2,3,5,10,12,18,20),into=c('survey','seasonal',
'state','area','supersector','industry',
'data_type'),
remove=F)
# limit to annual employment data and remove unnecessary columns
current <- current %>%
filter(period=='M13', data_type=='01', year==2019) %>%
select(-seasonal, -survey, -footnote_codes, -data_type, -year, -period)
current <- current %>%
filter(area!='00000', !grepl('.{4}4',area))
# pitt data
pitt_code <- cd_area %>%
filter(str_detect(area_name,'Pittsburgh')) %>%
pull(area_code)
pitt_emp <- current %>%
filter(area==pitt_code) %>%
select(supersector, industry, value) %>%
mutate(local_share = round(value/max(value),digits=5))
# msa aggregate
msa_agg <- current %>%
group_by(supersector, industry) %>%
summarise(agg_value = sum(value)) %>%
ungroup() %>%
mutate(agg_share = round(agg_value/max(agg_value),digits=5))
# combined
pitt_emp <- pitt_emp %>%
left_join(msa_agg, by=c('supersector','industry')) %>%
select(supersector, industry, value, local_share, agg_share)
# calculate lq
pitt_emp <- pitt_emp %>%
mutate(lq=round(local_share/agg_share,digits=3))
# primary metals example
primary_metals_code = '31331000'
pitt_emp %>%
filter(industry='331000')
View(pitt_emp)
pitt_emp %>%
filter(industry=='331000')
primary_metals <- pitt_emp %>%
filter(industry=='331000')
blogdown:::serve_site()
View(primary_metals)
View(pitt_emp)
View(pitt_emp)
pitt_emp %>%
mutate(theoretical = max(value) * agg_share,
diff = value - theoretical)
pitt_emp <- pitt_emp %>%
mutate(theoretical = max(value) * agg_share,
diff = value - theoretical)
current <- read_tsv(paste0(path_raw,'sm/sm_data_0_current.txt'))
current <- current %>%
separate(series_id, sep=c(2,3,5,10,12,18,20),into=c('survey','seasonal',
'state','area','supersector','industry',
'data_type'),
remove=F)
# limit to latest annual data
current <- current %>%
filter(period=='M13', year==2019)
# limit to msas
current <- current %>%
filter(area!='00000', !grepl('.{4}4',area))
employment <- current %>%
filter(data_type=='01')
wage_hour <- current %>%
filter(data_type %in% c('02','03'))
View(wage_hour)
wage_hour <- current %>%
filter(data_type == '11')
current %>% group_by(supersector, industry, data_type) %>% count()
test <- current %>% group_by(supersector, industry, data_type) %>% count()
View(test)
current %>% filter(industry != '000000') %>% group_by(data_type) %>%  count()
current %>% filter(supersector != '00') %>% group_by(data_type) %>%  count()
# constants
path_raw <- 'D:/Documents/data/fed_bls/employment/'
pa1 <- read_tsv(paste0(path_raw,'sm/sm_data_39a_Pennsylvania.txt'))
View(pa1)
pa1 <- pa1 %>%
separate(series_id, sep=c(2,3,5,10,12,18,20),into=c('survey','seasonal',
'state','area','supersector','industry',
'data_type'),
remove=F)
pa1 %>%
group_by(area, data_type) %>%
count()
pa1 %>%
group_by(data_type) %>%
count()
library(shiny)
library(nycflights13)
install.packages('nycflights13')
library(nycflights13)
library(tidyverse)
ua_data <-
nycflights13::flights %>%
filter(carrier == "UA") %>%
mutate(ind_arr_delay = (arr_delay > 5)) %>%
group_by(year, month, day) %>%
summarize(
n = n(),
across(ends_with("delay"), mean, na.rm = TRUE)
) %>%
ungroup()
head(ua_data)
viz_monthly <- function(df, y_var, threshhold = NULL) {
ggplot(df) +
aes(
x = .data[["day"]],
y = .data[[y_var]]
) +
geom_line() +
geom_hline(yintercept = threshhold, color = "red", linetype = 2) +
scale_x_continuous(breaks = seq(1, 29, by = 7)) +
theme_minimal()
}
ua_data %>%
filter(month == 3) %>%
viz_monthly("arr_delay", threshhold = 10)
text_ui <- function(id) {
fluidRow(
textOutput(NS(id, "text"))
)
}
text_server <- function(id, df, vbl, threshhold) {
moduleServer(id, function(input, output, session) {
n <- reactive({sum(df()[[vbl]] > threshhold)})
output$text <- renderText({
paste("In this month",
vbl,
"exceeded the average daily threshhold of",
threshhold,
"a total of",
n(),
"days")
})
})
}
text_demo <- function() {
df <- data.frame(day = 1:30, arr_delay = 1:30)
ui <- fluidPage(text_ui("x"))
server <- function(input, output, session) {
text_server("x", reactive({df}), "arr_delay", 15)
}
shinyApp(ui, server)
}
text_demo <- function() {
df <- data.frame(day = 1:30, arr_delay = 1:30)
ui <- fluidPage(text_ui("x"))
server <- function(input, output, session) {
text_server("x", reactive({df}), "arr_delay", 15)
}
shinyApp(ui, server)
}
text_demo()
source('D:/Documents/GitHub/briandatablog/shiny_example.R')
text_demo()
library(shiny)
library(nycflights13)
library(tidyverse)
ua_data <-
nycflights13::flights %>%
filter(carrier == "UA") %>%
mutate(ind_arr_delay = (arr_delay > 5)) %>%
group_by(year, month, day) %>%
summarize(
n = n(),
across(ends_with("delay"), mean, na.rm = TRUE)
) %>%
ungroup()
head(ua_data)
viz_monthly <- function(df, y_var, threshhold = NULL) {
ggplot(df) +
aes(
x = .data[["day"]],
y = .data[[y_var]]
) +
geom_line() +
geom_hline(yintercept = threshhold, color = "red", linetype = 2) +
scale_x_continuous(breaks = seq(1, 29, by = 7)) +
theme_minimal()
}
ua_data %>%
filter(month == 3) %>%
viz_monthly("arr_delay", threshhold = 10)
text_ui <- function(id) {
fluidRow(
textOutput(NS(id, "text"))
)
}
text_server <- function(id, df, vbl, threshhold) {
moduleServer(id, function(input, output, session) {
n <- reactive({sum(df()[[vbl]] > threshhold)})
output$text <- renderText({
paste("In this month",
vbl,
"exceeded the average daily threshhold of",
threshhold,
"a total of",
n(),
"days")
})
})
}
text_demo <- function() {
df <- data.frame(day = 1:30, arr_delay = 1:30)
ui <- fluidPage(text_ui("x"))
server <- function(input, output, session) {
text_server("x", reactive({df}), "arr_delay", 15)
}
shinyApp(ui, server)
}
text_demo()
plot_ui <- function(id) {
fluidRow(
column(11, plotOutput(NS(id, "plot"))),
column( 1, downloadButton(NS(id, "dnld"), label = ""))
)
}
plot_server <- function(id, df, vbl, threshhold = NULL) {
moduleServer(id, function(input, output, session) {
plot <- reactive({viz_monthly(df(), vbl, threshhold)})
output$plot <- renderPlot({plot()})
output$dnld <- downloadHandler(
filename = function() {paste0(vbl, '.png')},
content = function(file) {ggsave(file, plot())}
)
})
}
plot_demo <- function() {
df <- data.frame(day = 1:30, arr_delay = 1:30)
ui <- fluidPage(plot_ui("x"))
server <- function(input, output, session) {
plot_server("x", reactive({df}), "arr_delay")
}
shinyApp(ui, server)
}
plot_demo()
metric_server <- function(id, df, vbl, threshhold) {
moduleServer(id, function(input, output, session) {
text_server("metric", df, vbl, threshhold)
plot_server("metric", df, vbl, threshhold)
})
}
metric_demo <- function() {
df <- data.frame(day = 1:30, arr_delay = 1:30)
ui <- fluidPage(metric_ui("x"))
server <- function(input, output, session) {
metric_server("x", reactive({df}), "arr_delay", 15)
}
shinyApp(ui, server)
}
metro_demo()
metric_demo()
metric_ui <- function(id) {
fluidRow(
text_ui(NS(id, "metric")),
plot_ui(NS(id, "metric"))
)
}
metric_server <- function(id, df, vbl, threshhold) {
moduleServer(id, function(input, output, session) {
text_server("metric", df, vbl, threshhold)
plot_server("metric", df, vbl, threshhold)
})
}
metric_demo <- function() {
df <- data.frame(day = 1:30, arr_delay = 1:30)
ui <- fluidPage(metric_ui("x"))
server <- function(input, output, session) {
metric_server("x", reactive({df}), "arr_delay", 15)
}
shinyApp(ui, server)
}
metric_demo()
ui <- fluidPage(
titlePanel("Flight Delay Report"),
sidebarLayout(
sidebarPanel = sidebarPanel(
selectInput("month", "Month",
choices = setNames(1:12, month.abb),
selected = 1
)
),
mainPanel = mainPanel(
h2(textOutput("title")),
h3("Average Departure Delay"),
metric_ui("dep_delay"),
h3("Average Arrival Delay"),
metric_ui("arr_delay"),
h3("Proportion Flights with >5 Min Arrival Delay"),
metric_ui("ind_arr_delay")
)
)
)
server <- function(input, output, session) {
output$title <- renderText({paste(month.abb[as.integer(input$month)], "Report")})
df_month <- reactive({filter(ua_data, month == input$month)})
metric_server("dep_delay", df_month, vbl = "dep_delay", threshhold = 10)
metric_server("arr_delay", df_month, vbl = "arr_delay", threshhold = 10)
metric_server("ind_arr_delay", df_month, vbl = "ind_arr_delay", threshhold = 0.5)
}
shinyApp(ui, server)
install.packages(c(
"gapminder", "ggforce", "openintro", "shiny", "shinycssloaders",
"shinyFeedback", "shinythemes", "thematic", "tidyverse", "vroom",
"waiter", "zeallot"
))
library(shiny)
blogdown:::serve_site()
install.packages('DT')
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
# libraries
library(tidyverse)
library(rmarkdown)
library(DT)
# load files
path_raw <- 'c:users/brian/Documents/data/fed_bls/employment/'
current <- read_tsv(paste0(path_raw,'sm/sm_data_0_current.txt'))
# libraries
library(tidyverse)
library(rmarkdown)
library(DT)
# load files
path_raw <- 'c:/users/brian/Documents/data/fed_bls/employment/'
current <- read_tsv(paste0(path_raw,'sm/sm_data_0_current.txt'))
cd_state <- read_tsv(paste0(path_raw,'sm/sm_state.txt'))
cd_area <- read_tsv(paste0(path_raw,'sm/sm_area.txt'))
cd_supersector <- read_tsv(paste0(path_raw,"sm/sm_supersector.txt"))
cd_industry <- read_tsv(paste0(path_raw,'sm/sm_industry.txt'))
# extract info from series_id
current <- current %>%
separate(series_id, sep=c(2,3,5,10,12,18,20),into=c('survey','seasonal',
'state','area','supersector','industry',
'data_type'),
remove=F)
# limit to latest annual data
current <- current %>%
filter(period=='M13', year==2019)
# limit to msas
current <- current %>%
filter(area!='00000', !grepl('.{4}4',area))
# create separate files for employment and hours_wages
employment <- current %>%
filter(data_type=='01')
wage_hour <- current %>%
filter(data_type == '11')
#  and remove unnecessary columns
# pitt data
pitt_code <- cd_area %>%
filter(str_detect(area_name,'Pittsburgh')) %>%
pull(area_code)
pitt_emp <- current %>%
filter(area==pitt_code) %>%
select(supersector, industry, value) %>%
mutate(local_share = round(value/max(value),digits=5))
# msa aggregate
msa_agg <- current %>%
group_by(supersector, industry) %>%
summarise(agg_value = sum(value)) %>%
ungroup() %>%
mutate(agg_share = round(agg_value/max(agg_value),digits=5))
# combined
pitt_emp <- pitt_emp %>%
left_join(msa_agg, by=c('supersector','industry')) %>%
select(supersector, industry, value, local_share, agg_share)
# calculate lq
pitt_emp <- pitt_emp %>%
mutate(lq=round(local_share/agg_share,digits=3))
# calculate theoretical employment based on aggregate model
pitt_emp <- pitt_emp %>%
mutate(theoretical = max(value) * agg_share,
diff = value - theoretical)
primary_metals <- pitt_emp %>%
filter(industry=='331000')
blogdown:::serve_site()
blogdown::install_hugo()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
gnd_cover <- tribble(
~code, ~desc,
'0','unknown',
'1','grass',
'2','fallow',
'3','bare ground',
'4','brome grass',
'5','sod',
'6','straw multch',
'7','grass muck',
'8','bare muck'
)
library(tidyverse)
gnd_cover <- tribble(
~code, ~desc,
'0','unknown',
'1','grass',
'2','fallow',
'3','bare ground',
'4','brome grass',
'5','sod',
'6','straw multch',
'7','grass muck',
'8','bare muck'
)
depth_codes <- tribble(
~code,~depth,
'1','5 cm',
'2','10 cm',
'3','20 cm',
'4','50 cm',
'5','100 cm',
'6','150 cm',
'7','180 cm'
)
library(tidyverse)
gnd_cover <- tribble(
~code, ~desc,
'0','unknown',
'1','grass',
'2','fallow',
'3','bare ground',
'4','brome grass',
'5','sod',
'6','straw multch',
'7','grass muck',
'8','bare muck'
)
depth_codes <- tribble(
~code,~depth,
'1','5 cm',
'2','10 cm',
'3','20 cm',
'4','50 cm',
'5','100 cm',
'6','150 cm',
'7','180 cm'
)
soil_temp_lookup <- bind_cols(unite(crossing("SN",gnd_cover$code,depth_codes$code),
soil_temp,sep=''),
unite(crossing(gnd_cover$desc,depth_codes$depth),desc,sep=", "))
soil_temp_lookup
